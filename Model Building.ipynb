{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMNjQtHYTyytgH94Qv434b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjung-stat/Customer-Support-Chat-Intent-Classification/blob/main/Model%20Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before building a text classification model using BERT, we need to preprocess the dataset. First of all, we do one-hot encoding on our target variable. And after that, we use one of the companions of BERT models which is designed to work alongside BERT models, and its purpose is to transform unprocessed textual inputs into the appropriate input format required by BERT. More details can be found below."
      ],
      "metadata": {
        "id": "LVwJO1k3Qn0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "ldQkLp1Sp5MS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preprocessed training and testing data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/df_training_complete.pkl', 'rb') as f:   # Load `df_training_complete` from Google Drive\n",
        "    df_training_complete = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/df_testing_copy.pkl', 'rb') as f:   # Load `df_testing_copy` from Google Drive\n",
        "    df_testing_complete = pickle.load(f)"
      ],
      "metadata": {
        "id": "hb5hqrr_oGd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d29239e-cbb7-45cc-bb4e-6f73df16c9c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "J1zqUDsqPNWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding"
      ],
      "metadata": {
        "id": "iR7r4DVISo3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training and validation sets and reformat testing set. \n",
        "trainfeatures, validfeatures, trainlabels, validlabels = train_test_split(df_training_complete['text'],df_training_complete['category'], stratify=df_training_complete['category'], test_size=0.2)\n",
        "\n",
        "testfeatures=df_testing_complete.copy()\n",
        "testlabels=testfeatures.pop(\"category\")\n",
        "\n",
        "\n",
        "# One-Hot-Encoding of class-labels\n",
        "binarizer=LabelBinarizer()  \n",
        "\n",
        "trainlabels=binarizer.fit_transform(trainlabels.values)\n",
        "validlabels=binarizer.transform(validlabels.values)\n",
        "testlabels=binarizer.transform(testlabels.values)\n",
        "trainfeatures = pd.DataFrame(trainfeatures)\n",
        "validfeatures = pd.DataFrame(validfeatures)"
      ],
      "metadata": {
        "id": "e6fmkh86oGgj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of training examples: \", trainfeatures.shape[0])\n",
        "print(\"Total number of validation examples: \", validfeatures.shape[0])\n",
        "print(\"Total number of testing examples: \", testfeatures.shape[0])"
      ],
      "metadata": {
        "id": "pzs-VVOQoGjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5484a9d8-eccc-4991-9984-7c8b691ccb51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training examples:  12733\n",
            "Total number of validation examples:  3184\n",
            "Total number of testing examples:  3080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow_text"
      ],
      "metadata": {
        "id": "iogh2xqcoGqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd1a2c5-bc84-4a30-df5a-7e80a53e927b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m311.7 kB/s\u001b[0m eta \u001b[36m0:00:19\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/5.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/5.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m5.2/5.8 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "SYkZje5BoGtJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the following preprocessing model cannot take pandas dataframe as input\n",
        "# Need to convert the input data (text) into list\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\") # The text data we will be working with will undergo preprocessing using a TensorFlow model.\n",
        "                                                                                              # As this preprocessor is a TensorFlow model, it can be easily integrated directly into your own model."
      ],
      "metadata": {
        "id": "tzk1kqUFoGwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd9d1f2-fc19-417f-d122-e45c9311bad3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3yY9yt3SUuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfSgMy7DSUxC",
        "outputId": "c809221f-8be1-41b8-b55f-ca6fd93a0d9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "7XEdmyl2Vsli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this intent classification project, we use BERT which is a pretrained language model. BERT is useful for intent classification because it is pre-trained on a large corpus of text data, allowing it to understand the nuances of natural language. Additionally, BERT uses a bidirectional approach, which means it can analyze a text input in both directions, allowing it to better understand the context and meaning of the input. By using BERT as a pre-processing step, you can improve the accuracy and efficiency of your intent classification model."
      ],
      "metadata": {
        "id": "sztDJsvFVzM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "-Tkha_rxSUzk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_classification_bert():\n",
        "  \n",
        "  # Initializing the BERT layers\n",
        "  input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text') # define an input tensor --> the input data to the model will be a string of variable length\n",
        "  text_preprocessed = bert_preprocess(input_text) # This layer converts the input string into a format that can be understood by the BERT model\n",
        "  output_bert = bert_model(text_preprocessed) # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                              # After that, this will be fed into the neural network layers.\n",
        "\n",
        "  # Initializing the neural network layers\n",
        "  encoded_text = output_bert['pooled_output']\n",
        "  layer_1 = tf.keras.layers.Dense(512, activation='relu')(encoded_text)\n",
        "  layer_2 = tf.keras.layers.Dense(256, activation='relu')(layer_1)\n",
        "  layer_3 = tf.keras.layers.Dense(128, activation='relu')(layer_2)\n",
        "  layer_4 = tf.keras.layers.Dropout(0.1)(layer_3) # This layer will be used to prevent model overfitting\n",
        "                                                                                 # We will use 0.1% of the neurons to handle overfitting\n",
        "  output = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(layer_4)  # It only has one neuron. We also initialize the activation function as sigmoid. \n",
        "                                                                                 # sigmoid is used when we have output values that between 0 and 1. \n",
        "                                                                                 # In our case, when making predictions, \n",
        "                                                                                 # the prediction probability will lie between 0 and 1. That’s why it is best suited.\n",
        "                                                                                 # We also name the layer as output because this is our output layer.\n",
        "  return tf.keras.Model(input_text, output)"
      ],
      "metadata": {
        "id": "OUN8D3SiSU2J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = intent_classification_bert()\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True) # Since this is a non-binary classification problem and the model outputs probabilities, \n",
        "                                                                 # you’ll use losses.CategoricalCrossentropy loss function.\n",
        "metrics = tf.metrics.CategoricalAccuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOCI10Y6SU4S",
        "outputId": "914e5ff2-f105-442b-86db-9450edac290a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "optimizer=tf.keras.optimizers.Adam(1e-5)\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "zEcVTpzZSU63"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier_model.fit(x=trainfeatures, y=trainlabels,\n",
        "                               validation_data=(validfeatures,validlabels),\n",
        "                               batch_size=32,\n",
        "                               #class_weight=class_weights_dict,\n",
        "                               epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpKPOFsDSU9H",
        "outputId": "01b54abc-dd06-42e5-9680-6b013123cf24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "398/398 [==============================] - ETA: 0s - loss: 2.5312 - categorical_accuracy: 0.1350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r398/398 [==============================] - 99s 219ms/step - loss: 2.5312 - categorical_accuracy: 0.1350 - val_loss: 2.4293 - val_categorical_accuracy: 0.2220\n",
            "Epoch 2/20\n",
            "398/398 [==============================] - 87s 218ms/step - loss: 2.3493 - categorical_accuracy: 0.2544 - val_loss: 2.2450 - val_categorical_accuracy: 0.3194\n",
            "Epoch 3/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 2.1798 - categorical_accuracy: 0.3273 - val_loss: 2.0829 - val_categorical_accuracy: 0.3728\n",
            "Epoch 4/20\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 2.0371 - categorical_accuracy: 0.3653 - val_loss: 1.9543 - val_categorical_accuracy: 0.4130\n",
            "Epoch 5/20\n",
            "398/398 [==============================] - 87s 218ms/step - loss: 1.9231 - categorical_accuracy: 0.4022 - val_loss: 1.8528 - val_categorical_accuracy: 0.4400\n",
            "Epoch 6/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.8315 - categorical_accuracy: 0.4286 - val_loss: 1.7696 - val_categorical_accuracy: 0.4614\n",
            "Epoch 7/20\n",
            "398/398 [==============================] - 87s 220ms/step - loss: 1.7533 - categorical_accuracy: 0.4540 - val_loss: 1.6989 - val_categorical_accuracy: 0.4843\n",
            "Epoch 8/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.6893 - categorical_accuracy: 0.4766 - val_loss: 1.6381 - val_categorical_accuracy: 0.5025\n",
            "Epoch 9/20\n",
            "398/398 [==============================] - 87s 217ms/step - loss: 1.6306 - categorical_accuracy: 0.4912 - val_loss: 1.5833 - val_categorical_accuracy: 0.5229\n",
            "Epoch 10/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.5839 - categorical_accuracy: 0.5054 - val_loss: 1.5397 - val_categorical_accuracy: 0.5292\n",
            "Epoch 11/20\n",
            "398/398 [==============================] - 86s 215ms/step - loss: 1.5430 - categorical_accuracy: 0.5193 - val_loss: 1.5012 - val_categorical_accuracy: 0.5349\n",
            "Epoch 12/20\n",
            "398/398 [==============================] - 81s 204ms/step - loss: 1.5006 - categorical_accuracy: 0.5319 - val_loss: 1.4654 - val_categorical_accuracy: 0.5540\n",
            "Epoch 13/20\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 1.4675 - categorical_accuracy: 0.5410 - val_loss: 1.4320 - val_categorical_accuracy: 0.5625\n",
            "Epoch 14/20\n",
            "398/398 [==============================] - 87s 219ms/step - loss: 1.4385 - categorical_accuracy: 0.5490 - val_loss: 1.4095 - val_categorical_accuracy: 0.5669\n",
            "Epoch 15/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.4036 - categorical_accuracy: 0.5622 - val_loss: 1.3770 - val_categorical_accuracy: 0.5810\n",
            "Epoch 16/20\n",
            "398/398 [==============================] - 86s 216ms/step - loss: 1.3851 - categorical_accuracy: 0.5667 - val_loss: 1.3545 - val_categorical_accuracy: 0.5823\n",
            "Epoch 17/20\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 1.3565 - categorical_accuracy: 0.5804 - val_loss: 1.3331 - val_categorical_accuracy: 0.5864\n",
            "Epoch 18/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.3306 - categorical_accuracy: 0.5844 - val_loss: 1.3143 - val_categorical_accuracy: 0.5886\n",
            "Epoch 19/20\n",
            "398/398 [==============================] - 85s 215ms/step - loss: 1.3102 - categorical_accuracy: 0.5867 - val_loss: 1.2982 - val_categorical_accuracy: 0.5930\n",
            "Epoch 20/20\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 1.2881 - categorical_accuracy: 0.5946 - val_loss: 1.2769 - val_categorical_accuracy: 0.6077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YejhDbid3vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DmSmaH0d30G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDukoofJd32l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}