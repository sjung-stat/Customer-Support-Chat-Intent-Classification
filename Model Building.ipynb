{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5cJm2Um6Av4YLxSO9/2Hr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjung-stat/Customer-Support-Chat-Intent-Classification/blob/main/Model%20Building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before building a text classification model using BERT, we need to preprocess the dataset. First of all, we do one-hot encoding on our target variable. And after that, we use one of the companions of BERT models which is designed to work alongside BERT models, and its purpose is to transform unprocessed textual inputs into the appropriate input format required by BERT. More details can be found below."
      ],
      "metadata": {
        "id": "LVwJO1k3Qn0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "ldQkLp1Sp5MS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the preprocessed training and testing data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/MyDrive/df_training_complete.pkl', 'rb') as f:   # Load `df_training_complete` from Google Drive\n",
        "    df_training_complete = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/df_testing_copy.pkl', 'rb') as f:   # Load `df_testing_copy` from Google Drive\n",
        "    df_testing_complete = pickle.load(f)"
      ],
      "metadata": {
        "id": "hb5hqrr_oGd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb18be8d-235d-4fa2-95bf-ffc0e5fa3436"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "J1zqUDsqPNWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Hot Encoding"
      ],
      "metadata": {
        "id": "iR7r4DVISo3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training and validation sets and reformat testing set. \n",
        "trainfeatures, validfeatures, trainlabels, validlabels = train_test_split(df_training_complete['text'],df_training_complete['category'], stratify=df_training_complete['category'], test_size=0.2)\n",
        "\n",
        "testfeatures=df_testing_complete.copy()\n",
        "testlabels=testfeatures.pop(\"category\")\n",
        "trainlabels_original= trainlabels.values\n",
        "\n",
        "\n",
        "# One-Hot-Encoding of class-labels\n",
        "binarizer=LabelBinarizer()  \n",
        "\n",
        "trainlabels=binarizer.fit_transform(trainlabels.values)\n",
        "validlabels=binarizer.transform(validlabels.values)\n",
        "testlabels=binarizer.transform(testlabels.values)\n",
        "trainfeatures = pd.DataFrame(trainfeatures)\n",
        "validfeatures = pd.DataFrame(validfeatures)"
      ],
      "metadata": {
        "id": "e6fmkh86oGgj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of training examples: \", trainfeatures.shape[0])\n",
        "print(\"Total number of validation examples: \", validfeatures.shape[0])\n",
        "print(\"Total number of testing examples: \", testfeatures.shape[0])"
      ],
      "metadata": {
        "id": "pzs-VVOQoGjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6580484c-1516-4720-eef3-3cc66a912984"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training examples:  12733\n",
            "Total number of validation examples:  3184\n",
            "Total number of testing examples:  3080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow_text"
      ],
      "metadata": {
        "id": "iogh2xqcoGqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2f417b-98c4-4f91-c481-e12730663bd6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/5.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/5.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/5.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m4.8/5.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SYkZje5BoGtJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N_fMoGNFNF_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "7XEdmyl2Vsli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this intent classification project, we use BERT which is a pretrained language model. BERT is useful for intent classification because it is pre-trained on a large corpus of text data, allowing it to understand the nuances of natural language. Additionally, BERT uses a bidirectional approach, which means it can analyze a text input in both directions, allowing it to better understand the context and meaning of the input. By using BERT as a pre-processing step, you can improve the accuracy and efficiency of your intent classification model."
      ],
      "metadata": {
        "id": "sztDJsvFVzM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1"
      ],
      "metadata": {
        "id": "3cNQ3vfsNjIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the following preprocessing model cannot take pandas dataframe as input\n",
        "# Need to convert the input data (text) into list\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\") # The text data we will be working with will undergo preprocessing using a TensorFlow model.\n",
        "                                                                                              # As this preprocessor is a TensorFlow model, it can be easily integrated directly into your own model.\n",
        "bert_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "tzk1kqUFoGwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a354a5c5-d335-4506-e083-2b791b21d5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed = bert_preprocess(input_text)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert = bert_model(text_preprocessed)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output = output_bert['sequence_output']\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling = tf.keras.layers.GlobalAveragePooling1D()(sequence_output)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_avg_pooling = tf.keras.layers.Concatenate()([avg_pooling, output_bert['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_avg_pooling = tf.keras.layers.Dense(512, activation='relu')(concatenated_avg_pooling)\n",
        "dense_2_avg_pooling = tf.keras.layers.Dense(256, activation='relu')(dense_1_avg_pooling)\n",
        "dense_3_avg_pooling = tf.keras.layers.Dense(128, activation='relu')(dense_2_avg_pooling)\n",
        "dense_4_avg_pooling = tf.keras.layers.Dropout(0.1)(dense_3_avg_pooling)\n",
        "\n",
        "# Define output layer\n",
        "output_avg_pooling = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_4_avg_pooling)\n",
        "\n",
        "# Define the model\n",
        "model_avg_pooling = tf.keras.Model(inputs=input_text, outputs=output_avg_pooling)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model.trainable = False  # sets the BERT model's trainable attribute to False, which freezes the weights of the BERT layers. \n",
        "                              # This means that during training, the weights of the BERT layers will not be updated. \n",
        "                              # Freezing the BERT layers can be beneficial when the dataset used to fine-tune BERT is small or when the task-specific layers have not converged yet. \n",
        "                              # Freezing the BERT layers allows the model to focus on learning the task-specific layers without overfitting to the small dataset or disrupting the already learned BERT weights.\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_avg_pooling.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EGe0mYv5-LCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "DzRcGR4F-LFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_avg_pooling.fit(train_dataset, epochs=30, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpUixkIeujlO",
        "outputId": "d846c642-bd70-45bf-d8a9-e6c611fe4d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 86s 201ms/step - loss: 2.0331 - accuracy: 0.3683 - val_loss: 1.5259 - val_accuracy: 0.5355\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 1.3135 - accuracy: 0.5941 - val_loss: 1.1253 - val_accuracy: 0.6636\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 78s 195ms/step - loss: 1.0502 - accuracy: 0.6715 - val_loss: 0.9479 - val_accuracy: 0.7249\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 78s 197ms/step - loss: 0.9031 - accuracy: 0.7177 - val_loss: 0.8546 - val_accuracy: 0.7437\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 78s 195ms/step - loss: 0.8081 - accuracy: 0.7443 - val_loss: 0.7900 - val_accuracy: 0.7579\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.7332 - accuracy: 0.7707 - val_loss: 0.7433 - val_accuracy: 0.7692\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 83s 209ms/step - loss: 0.6840 - accuracy: 0.7839 - val_loss: 0.6987 - val_accuracy: 0.7827\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 79s 197ms/step - loss: 0.6284 - accuracy: 0.7989 - val_loss: 0.6638 - val_accuracy: 0.7930\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.5880 - accuracy: 0.8120 - val_loss: 0.6381 - val_accuracy: 0.8021\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 78s 197ms/step - loss: 0.5532 - accuracy: 0.8255 - val_loss: 0.6201 - val_accuracy: 0.8031\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.5188 - accuracy: 0.8359 - val_loss: 0.5907 - val_accuracy: 0.8090\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.4913 - accuracy: 0.8471 - val_loss: 0.5814 - val_accuracy: 0.8160\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 83s 209ms/step - loss: 0.4661 - accuracy: 0.8544 - val_loss: 0.5665 - val_accuracy: 0.8188\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 79s 200ms/step - loss: 0.4454 - accuracy: 0.8584 - val_loss: 0.5525 - val_accuracy: 0.8244\n",
            "Epoch 15/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.4210 - accuracy: 0.8673 - val_loss: 0.5466 - val_accuracy: 0.8273\n",
            "Epoch 16/30\n",
            "398/398 [==============================] - 79s 200ms/step - loss: 0.3968 - accuracy: 0.8768 - val_loss: 0.5266 - val_accuracy: 0.8379\n",
            "Epoch 17/30\n",
            "398/398 [==============================] - 80s 202ms/step - loss: 0.3740 - accuracy: 0.8835 - val_loss: 0.5141 - val_accuracy: 0.8373\n",
            "Epoch 18/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.3584 - accuracy: 0.8886 - val_loss: 0.5103 - val_accuracy: 0.8414\n",
            "Epoch 19/30\n",
            "398/398 [==============================] - 84s 211ms/step - loss: 0.3415 - accuracy: 0.8937 - val_loss: 0.5091 - val_accuracy: 0.8367\n",
            "Epoch 20/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.3260 - accuracy: 0.9005 - val_loss: 0.5003 - val_accuracy: 0.8395\n",
            "Epoch 21/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.3099 - accuracy: 0.9059 - val_loss: 0.4914 - val_accuracy: 0.8423\n",
            "Epoch 22/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.2942 - accuracy: 0.9130 - val_loss: 0.4846 - val_accuracy: 0.8483\n",
            "Epoch 23/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.2841 - accuracy: 0.9124 - val_loss: 0.4816 - val_accuracy: 0.8470\n",
            "Epoch 24/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.2687 - accuracy: 0.9191 - val_loss: 0.4800 - val_accuracy: 0.8508\n",
            "Epoch 25/30\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 0.2591 - accuracy: 0.9225 - val_loss: 0.4701 - val_accuracy: 0.8527\n",
            "Epoch 26/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.2459 - accuracy: 0.9270 - val_loss: 0.4645 - val_accuracy: 0.8540\n",
            "Epoch 27/30\n",
            "398/398 [==============================] - 81s 203ms/step - loss: 0.2349 - accuracy: 0.9303 - val_loss: 0.4619 - val_accuracy: 0.8543\n",
            "Epoch 28/30\n",
            "398/398 [==============================] - 81s 203ms/step - loss: 0.2224 - accuracy: 0.9333 - val_loss: 0.4566 - val_accuracy: 0.8549\n",
            "Epoch 29/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.2154 - accuracy: 0.9355 - val_loss: 0.4661 - val_accuracy: 0.8599\n",
            "Epoch 30/30\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 0.2026 - accuracy: 0.9397 - val_loss: 0.4543 - val_accuracy: 0.8618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8ce24d250>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1lZ3XPro-LIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2"
      ],
      "metadata": {
        "id": "9JDN2kUBNmeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_v2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model_v2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "aj3jBLSS-LOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412c073f-e162-4cad-ae20-93dbc1b32ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text_v2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed_v2 = bert_preprocess_v2(input_text_v2)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert_v2 = bert_model_v2(text_preprocessed_v2)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output_v2 = output_bert_v2['sequence_output']\n",
        "\n",
        "# Apply max pooling over sequence output\n",
        "max_pooling_v2 = tf.keras.layers.GlobalMaxPooling1D()(sequence_output_v2)\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling_v2 = tf.keras.layers.GlobalAveragePooling1D()(sequence_output_v2)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_v2 = tf.keras.layers.Concatenate()([max_pooling_v2, avg_pooling_v2, output_bert_v2['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_v2 = tf.keras.layers.Dense(512, activation='relu')(concatenated_v2)\n",
        "dense_2_v2 = tf.keras.layers.Dense(256, activation='relu')(dense_1_v2)\n",
        "dense_3_v2 = tf.keras.layers.Dense(128, activation='relu')(dense_2_v2)\n",
        "dense_4_v2 = tf.keras.layers.Dropout(0.1)(dense_3_v2)\n",
        "\n",
        "# Define output layer\n",
        "output_v2 = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_4_v2)\n",
        "\n",
        "# Define the model\n",
        "model_max_avg_pooling = tf.keras.Model(inputs=input_text_v2, outputs=output_v2)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model_v2.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "optimizer_v2 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_max_avg_pooling.compile(optimizer=optimizer_v2, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CvvzXALx-LQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08cc5eb-a6b4-4e66-a8b8-111aa3225bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "NaW5nBZx-LTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_max_avg_pooling = model_max_avg_pooling.fit(train_dataset, epochs=30, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "77QZ-xaa-LWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db92c9b2-3571-487a-8ab5-c91b4f562ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 100s 225ms/step - loss: 1.9592 - accuracy: 0.3784 - val_loss: 1.4508 - val_accuracy: 0.5628\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.2809 - accuracy: 0.5976 - val_loss: 1.0911 - val_accuracy: 0.6731\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 81s 205ms/step - loss: 1.0375 - accuracy: 0.6771 - val_loss: 0.9266 - val_accuracy: 0.7192\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.8895 - accuracy: 0.7194 - val_loss: 0.8252 - val_accuracy: 0.7509\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 81s 204ms/step - loss: 0.7961 - accuracy: 0.7506 - val_loss: 0.7543 - val_accuracy: 0.7701\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 85s 215ms/step - loss: 0.7169 - accuracy: 0.7753 - val_loss: 0.6989 - val_accuracy: 0.7855\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 0.6585 - accuracy: 0.7920 - val_loss: 0.6558 - val_accuracy: 0.7927\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.6081 - accuracy: 0.8081 - val_loss: 0.6244 - val_accuracy: 0.8031\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 85s 212ms/step - loss: 0.5666 - accuracy: 0.8201 - val_loss: 0.5833 - val_accuracy: 0.8094\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.5252 - accuracy: 0.8319 - val_loss: 0.5665 - val_accuracy: 0.8232\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 85s 215ms/step - loss: 0.4931 - accuracy: 0.8483 - val_loss: 0.5343 - val_accuracy: 0.8317\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 81s 202ms/step - loss: 0.4625 - accuracy: 0.8547 - val_loss: 0.5267 - val_accuracy: 0.8351\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 82s 205ms/step - loss: 0.4357 - accuracy: 0.8630 - val_loss: 0.5199 - val_accuracy: 0.8335\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 0.4155 - accuracy: 0.8732 - val_loss: 0.5060 - val_accuracy: 0.8361\n",
            "Epoch 15/30\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 0.3928 - accuracy: 0.8763 - val_loss: 0.5019 - val_accuracy: 0.8439\n",
            "Epoch 16/30\n",
            "398/398 [==============================] - 83s 208ms/step - loss: 0.3696 - accuracy: 0.8841 - val_loss: 0.4891 - val_accuracy: 0.8455\n",
            "Epoch 17/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.3500 - accuracy: 0.8930 - val_loss: 0.4867 - val_accuracy: 0.8436\n",
            "Epoch 18/30\n",
            "398/398 [==============================] - 85s 212ms/step - loss: 0.3319 - accuracy: 0.8988 - val_loss: 0.4685 - val_accuracy: 0.8511\n",
            "Epoch 19/30\n",
            "398/398 [==============================] - 84s 211ms/step - loss: 0.3103 - accuracy: 0.9072 - val_loss: 0.4633 - val_accuracy: 0.8486\n",
            "Epoch 20/30\n",
            "398/398 [==============================] - 85s 215ms/step - loss: 0.2950 - accuracy: 0.9090 - val_loss: 0.4358 - val_accuracy: 0.8646\n",
            "Epoch 21/30\n",
            "398/398 [==============================] - 81s 203ms/step - loss: 0.2782 - accuracy: 0.9162 - val_loss: 0.4503 - val_accuracy: 0.8596\n",
            "Epoch 22/30\n",
            "398/398 [==============================] - 80s 202ms/step - loss: 0.2675 - accuracy: 0.9193 - val_loss: 0.4443 - val_accuracy: 0.8602\n",
            "Epoch 23/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.2525 - accuracy: 0.9259 - val_loss: 0.4470 - val_accuracy: 0.8568\n",
            "Epoch 24/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.2394 - accuracy: 0.9288 - val_loss: 0.4401 - val_accuracy: 0.8634\n",
            "Epoch 25/30\n",
            "398/398 [==============================] - 80s 202ms/step - loss: 0.2250 - accuracy: 0.9333 - val_loss: 0.4366 - val_accuracy: 0.8628\n",
            "Epoch 26/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.2120 - accuracy: 0.9381 - val_loss: 0.4330 - val_accuracy: 0.8649\n",
            "Epoch 27/30\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 0.2029 - accuracy: 0.9423 - val_loss: 0.4419 - val_accuracy: 0.8643\n",
            "Epoch 28/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.1931 - accuracy: 0.9441 - val_loss: 0.4178 - val_accuracy: 0.8722\n",
            "Epoch 29/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.1841 - accuracy: 0.9466 - val_loss: 0.4439 - val_accuracy: 0.8646\n",
            "Epoch 30/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.1765 - accuracy: 0.9478 - val_loss: 0.4109 - val_accuracy: 0.8775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_max_avg_pooling.history['accuracy'])\n",
        "plt.plot(history_max_avg_pooling.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ud72taMM-LZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5dcbe1c0-d555-456c-dc1b-35dde27bda84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 \n"
      ],
      "metadata": {
        "id": "EiUP5OKRnc5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# consider 'early stopping'\n",
        "# consider 'another dropout\n",
        "# consider taking into account the weights of the classes"
      ],
      "metadata": {
        "id": "_YaSkG5fk3Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_v3 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model_v3 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "8-P_M6rJk3SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text_v3 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed_v3 = bert_preprocess_v2(input_text_v3)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert_v3 = bert_model_v3(text_preprocessed_v3)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output_v3 = output_bert_v3['sequence_output']\n",
        "\n",
        "# Apply max pooling over sequence output\n",
        "max_pooling_v3 = tf.keras.layers.GlobalMaxPooling1D()(sequence_output_v3)\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling_v3 = tf.keras.layers.GlobalAveragePooling1D()(sequence_output_v3)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_v3 = tf.keras.layers.Concatenate()([max_pooling_v3, avg_pooling_v3, output_bert_v3['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_v3 = tf.keras.layers.Dense(512, activation='relu')(concatenated_v3)\n",
        "dense_2_v3 = tf.keras.layers.Dense(256, activation='relu')(dense_1_v3)\n",
        "dense_3_v3 = tf.keras.layers.Dropout(0.1)(dense_2_v3)\n",
        "dense_4_v3 = tf.keras.layers.Dense(128, activation='relu')(dense_3_v3)\n",
        "dense_5_v3 = tf.keras.layers.Dropout(0.1)(dense_4_v3)\n",
        "\n",
        "# Define output layer\n",
        "output_v3 = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_5_v3)\n",
        "\n",
        "# Define the model\n",
        "model_max_avg_pooling_v3 = tf.keras.Model(inputs=input_text_v3, outputs=output_v3)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model_v3.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "optimizer_v3 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_max_avg_pooling_v3.compile(optimizer=optimizer_v3, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "fwUbZB3Wk3Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "rBdfoV8ANuri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_max_avg_pooling_v3 = model_max_avg_pooling_v3.fit(train_dataset, epochs=30, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRbwjFovudHK",
        "outputId": "220c4bc3-302f-4622-cc8c-e532307aeee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 92s 211ms/step - loss: 2.0549 - accuracy: 0.3404 - val_loss: 1.5031 - val_accuracy: 0.5503\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 84s 210ms/step - loss: 1.3705 - accuracy: 0.5633 - val_loss: 1.1243 - val_accuracy: 0.6476\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 1.1046 - accuracy: 0.6493 - val_loss: 0.9463 - val_accuracy: 0.7082\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.9454 - accuracy: 0.7001 - val_loss: 0.8389 - val_accuracy: 0.7321\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 79s 200ms/step - loss: 0.8469 - accuracy: 0.7312 - val_loss: 0.7608 - val_accuracy: 0.7594\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 83s 208ms/step - loss: 0.7698 - accuracy: 0.7572 - val_loss: 0.6999 - val_accuracy: 0.7783\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.7116 - accuracy: 0.7741 - val_loss: 0.6635 - val_accuracy: 0.7886\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 80s 202ms/step - loss: 0.6583 - accuracy: 0.7913 - val_loss: 0.6256 - val_accuracy: 0.7993\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 84s 212ms/step - loss: 0.6073 - accuracy: 0.8043 - val_loss: 0.6135 - val_accuracy: 0.8018\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.5748 - accuracy: 0.8193 - val_loss: 0.5809 - val_accuracy: 0.8147\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.5369 - accuracy: 0.8269 - val_loss: 0.5514 - val_accuracy: 0.8210\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.5063 - accuracy: 0.8427 - val_loss: 0.5280 - val_accuracy: 0.8279\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 80s 200ms/step - loss: 0.4824 - accuracy: 0.8469 - val_loss: 0.5146 - val_accuracy: 0.8326\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 0.4523 - accuracy: 0.8590 - val_loss: 0.5078 - val_accuracy: 0.8376\n",
            "Epoch 15/30\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 0.4296 - accuracy: 0.8650 - val_loss: 0.5074 - val_accuracy: 0.8367\n",
            "Epoch 16/30\n",
            "398/398 [==============================] - 78s 197ms/step - loss: 0.4069 - accuracy: 0.8728 - val_loss: 0.4858 - val_accuracy: 0.8445\n",
            "Epoch 17/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.3851 - accuracy: 0.8804 - val_loss: 0.4699 - val_accuracy: 0.8521\n",
            "Epoch 18/30\n",
            "398/398 [==============================] - 78s 195ms/step - loss: 0.3625 - accuracy: 0.8872 - val_loss: 0.4721 - val_accuracy: 0.8508\n",
            "Epoch 19/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.3441 - accuracy: 0.8941 - val_loss: 0.4781 - val_accuracy: 0.8470\n",
            "Epoch 20/30\n",
            "398/398 [==============================] - 78s 196ms/step - loss: 0.3268 - accuracy: 0.8981 - val_loss: 0.4579 - val_accuracy: 0.8514\n",
            "Epoch 21/30\n",
            "398/398 [==============================] - 79s 199ms/step - loss: 0.3121 - accuracy: 0.9030 - val_loss: 0.4748 - val_accuracy: 0.8489\n",
            "Epoch 22/30\n",
            "398/398 [==============================] - 79s 200ms/step - loss: 0.3019 - accuracy: 0.9037 - val_loss: 0.4489 - val_accuracy: 0.8580\n",
            "Epoch 23/30\n",
            "336/398 [========================>.....] - ETA: 9s - loss: 0.2808 - accuracy: 0.9146 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_max_avg_pooling_v3.history['accuracy'])\n",
        "plt.plot(history_max_avg_pooling_v3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y_69tWh5udJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Avjf3X_udMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3fTjn7FudOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: early stopping = 3"
      ],
      "metadata": {
        "id": "BkgM8eq6wUaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping"
      ],
      "metadata": {
        "id": "KyfYjh0OM01Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_v4 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model_v4 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQ8BDjKM039",
        "outputId": "4faac99f-a4a2-4d08-f54b-875cec103df6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text_v4 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed_v4 = bert_preprocess_v4(input_text_v4)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert_v4 = bert_model_v4(text_preprocessed_v4)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output_v4 = output_bert_v4['sequence_output']\n",
        "\n",
        "# Apply max pooling over sequence output\n",
        "max_pooling_v4 = tf.keras.layers.GlobalMaxPooling1D()(sequence_output_v4)\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling_v4 = tf.keras.layers.GlobalAveragePooling1D()(sequence_output_v4)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_v4 = tf.keras.layers.Concatenate()([max_pooling_v4, avg_pooling_v4, output_bert_v4['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_v4 = tf.keras.layers.Dense(512, activation='relu')(concatenated_v4)\n",
        "dense_2_v4 = tf.keras.layers.Dense(256, activation='relu')(dense_1_v4)\n",
        "dense_3_v4 = tf.keras.layers.Dropout(0.1)(dense_2_v4)\n",
        "dense_4_v4 = tf.keras.layers.Dense(128, activation='relu')(dense_3_v4)\n",
        "dense_5_v4 = tf.keras.layers.Dropout(0.1)(dense_4_v4)\n",
        "\n",
        "# Define output layer\n",
        "output_v4 = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_5_v4)\n",
        "\n",
        "# Define the model\n",
        "model_max_avg_pooling_v4 = tf.keras.Model(inputs=input_text_v4, outputs=output_v4)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model_v4.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "optimizer_v4 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_max_avg_pooling_v4.compile(optimizer=optimizer_v4, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3B6CCDIM4Yz",
        "outputId": "a421f751-7d41-4e60-9c25-777238517df1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import EarlyStopping callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "earlystop_callback = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=3,          # Stop training if validation loss does not improve for 3 epochs\n",
        "    restore_best_weights=True   # Restore the weights of the best epoch\n",
        ")"
      ],
      "metadata": {
        "id": "o0ekhJBvN6Q_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "UrJzYutUM4bM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_max_avg_pooling_v4 = model_max_avg_pooling_v4.fit(train_dataset, epochs=30, validation_data=val_dataset, callbacks=[earlystop_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMEBmNEaM4dr",
        "outputId": "5bd85fea-922a-4808-b525-314fa17b3b52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 93s 203ms/step - loss: 2.0620 - accuracy: 0.3441 - val_loss: 1.5780 - val_accuracy: 0.5188\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 1.3926 - accuracy: 0.5607 - val_loss: 1.1754 - val_accuracy: 0.6410\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 1.1229 - accuracy: 0.6451 - val_loss: 1.0163 - val_accuracy: 0.6866\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.9623 - accuracy: 0.6939 - val_loss: 0.9044 - val_accuracy: 0.7195\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.8579 - accuracy: 0.7270 - val_loss: 0.8255 - val_accuracy: 0.7465\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 0.7772 - accuracy: 0.7567 - val_loss: 0.7919 - val_accuracy: 0.7553\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.7180 - accuracy: 0.7751 - val_loss: 0.7485 - val_accuracy: 0.7644\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.6524 - accuracy: 0.7982 - val_loss: 0.6964 - val_accuracy: 0.7817\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 0.6140 - accuracy: 0.8036 - val_loss: 0.6668 - val_accuracy: 0.7971\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.5663 - accuracy: 0.8222 - val_loss: 0.6376 - val_accuracy: 0.7990\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.5309 - accuracy: 0.8354 - val_loss: 0.5997 - val_accuracy: 0.8138\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 0.5049 - accuracy: 0.8410 - val_loss: 0.6062 - val_accuracy: 0.8109\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 0.4785 - accuracy: 0.8512 - val_loss: 0.6127 - val_accuracy: 0.8125\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.4485 - accuracy: 0.8578 - val_loss: 0.6045 - val_accuracy: 0.8150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_max_avg_pooling_v4.history['accuracy'])\n",
        "plt.plot(history_max_avg_pooling_v4.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "DMIxtO80M4gB",
        "outputId": "d916c249-9728-427c-f3b2-98a9ee59089d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqqpBb9FM07D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jozEwJLpM09R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KAD7bfeM0_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYsRFDdhM1CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4-2: Early stopping = 5"
      ],
      "metadata": {
        "id": "0k-W8Uj-U9YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_v5 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model_v5 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "PlXwBoyrUnHr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text_v5 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed_v5 = bert_preprocess_v5(input_text_v5)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert_v5 = bert_model_v5(text_preprocessed_v5)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output_v5 = output_bert_v5['sequence_output']\n",
        "\n",
        "# Apply max pooling over sequence output\n",
        "max_pooling_v5 = tf.keras.layers.GlobalMaxPooling1D()(sequence_output_v5)\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling_v5 = tf.keras.layers.GlobalAveragePooling1D()(sequence_output_v5)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_v5 = tf.keras.layers.Concatenate()([max_pooling_v5, avg_pooling_v5, output_bert_v5['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_v5 = tf.keras.layers.Dense(512, activation='relu')(concatenated_v5)\n",
        "dense_2_v5 = tf.keras.layers.Dense(256, activation='relu')(dense_1_v5)\n",
        "dense_3_v5 = tf.keras.layers.Dropout(0.1)(dense_2_v5)\n",
        "dense_4_v5 = tf.keras.layers.Dense(128, activation='relu')(dense_3_v5)\n",
        "dense_5_v5 = tf.keras.layers.Dropout(0.1)(dense_4_v5)\n",
        "\n",
        "# Define output layer\n",
        "output_v5 = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_5_v5)\n",
        "\n",
        "# Define the model\n",
        "model_max_avg_pooling_v5 = tf.keras.Model(inputs=input_text_v5, outputs=output_v5)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model_v5.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "optimizer_v5 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_max_avg_pooling_v5.compile(optimizer=optimizer_v5, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z17ix1dLUnKF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import EarlyStopping callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "earlystop_callback = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop training if validation loss does not improve for 5 epochs\n",
        "    restore_best_weights=True   # Restore the weights of the best epoch\n",
        ")"
      ],
      "metadata": {
        "id": "RYh3HKyiUnMi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "DQ6A4g0PUuwU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_max_avg_pooling_v5 = model_max_avg_pooling_v5.fit(train_dataset, epochs=30, validation_data=val_dataset, callbacks=[earlystop_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l_pMJJ9Uuy1",
        "outputId": "74bf4e3d-0d70-4d1e-8dff-d05149091710"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 86s 195ms/step - loss: 2.0559 - accuracy: 0.3327 - val_loss: 1.5738 - val_accuracy: 0.5097\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 1.4119 - accuracy: 0.5433 - val_loss: 1.1825 - val_accuracy: 0.6335\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 1.1280 - accuracy: 0.6357 - val_loss: 1.0080 - val_accuracy: 0.6897\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 0.9682 - accuracy: 0.6907 - val_loss: 0.9112 - val_accuracy: 0.7095\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.8590 - accuracy: 0.7316 - val_loss: 0.8349 - val_accuracy: 0.7396\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 0.7811 - accuracy: 0.7521 - val_loss: 0.7625 - val_accuracy: 0.7607\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 76s 191ms/step - loss: 0.7144 - accuracy: 0.7748 - val_loss: 0.7025 - val_accuracy: 0.7808\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 76s 190ms/step - loss: 0.6655 - accuracy: 0.7878 - val_loss: 0.6723 - val_accuracy: 0.7902\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.6231 - accuracy: 0.7982 - val_loss: 0.6554 - val_accuracy: 0.7927\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.5767 - accuracy: 0.8172 - val_loss: 0.6167 - val_accuracy: 0.8024\n",
            "Epoch 11/30\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 0.5472 - accuracy: 0.8261 - val_loss: 0.6025 - val_accuracy: 0.8065\n",
            "Epoch 12/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.5178 - accuracy: 0.8362 - val_loss: 0.5947 - val_accuracy: 0.8141\n",
            "Epoch 13/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.4795 - accuracy: 0.8473 - val_loss: 0.5683 - val_accuracy: 0.8197\n",
            "Epoch 14/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.4582 - accuracy: 0.8549 - val_loss: 0.5627 - val_accuracy: 0.8185\n",
            "Epoch 15/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.4332 - accuracy: 0.8637 - val_loss: 0.5403 - val_accuracy: 0.8295\n",
            "Epoch 16/30\n",
            "398/398 [==============================] - 76s 192ms/step - loss: 0.4144 - accuracy: 0.8719 - val_loss: 0.5459 - val_accuracy: 0.8273\n",
            "Epoch 17/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.3901 - accuracy: 0.8773 - val_loss: 0.5251 - val_accuracy: 0.8317\n",
            "Epoch 18/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.3633 - accuracy: 0.8884 - val_loss: 0.5156 - val_accuracy: 0.8317\n",
            "Epoch 19/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.3496 - accuracy: 0.8902 - val_loss: 0.5257 - val_accuracy: 0.8335\n",
            "Epoch 20/30\n",
            "398/398 [==============================] - 76s 190ms/step - loss: 0.3307 - accuracy: 0.9005 - val_loss: 0.4951 - val_accuracy: 0.8445\n",
            "Epoch 21/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.3192 - accuracy: 0.9006 - val_loss: 0.4959 - val_accuracy: 0.8436\n",
            "Epoch 22/30\n",
            "398/398 [==============================] - 77s 192ms/step - loss: 0.2978 - accuracy: 0.9100 - val_loss: 0.5269 - val_accuracy: 0.8335\n",
            "Epoch 23/30\n",
            "398/398 [==============================] - 83s 208ms/step - loss: 0.2818 - accuracy: 0.9139 - val_loss: 0.4806 - val_accuracy: 0.8492\n",
            "Epoch 24/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.2699 - accuracy: 0.9193 - val_loss: 0.4877 - val_accuracy: 0.8414\n",
            "Epoch 25/30\n",
            "398/398 [==============================] - 76s 191ms/step - loss: 0.2513 - accuracy: 0.9250 - val_loss: 0.4674 - val_accuracy: 0.8492\n",
            "Epoch 26/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.2429 - accuracy: 0.9262 - val_loss: 0.4851 - val_accuracy: 0.8492\n",
            "Epoch 27/30\n",
            "398/398 [==============================] - 78s 195ms/step - loss: 0.2307 - accuracy: 0.9299 - val_loss: 0.4798 - val_accuracy: 0.8505\n",
            "Epoch 28/30\n",
            "398/398 [==============================] - 77s 193ms/step - loss: 0.2193 - accuracy: 0.9341 - val_loss: 0.4693 - val_accuracy: 0.8508\n",
            "Epoch 29/30\n",
            "398/398 [==============================] - 77s 194ms/step - loss: 0.2055 - accuracy: 0.9383 - val_loss: 0.4726 - val_accuracy: 0.8527\n",
            "Epoch 30/30\n",
            "398/398 [==============================] - 76s 191ms/step - loss: 0.1962 - accuracy: 0.9422 - val_loss: 0.4627 - val_accuracy: 0.8562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_max_avg_pooling_v5.history['accuracy'])\n",
        "plt.plot(history_max_avg_pooling_v5.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yV0ZJAnhUu1Q",
        "outputId": "34e037ad-d1d8-44d6-c292-6b1e5adf6778"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EgHvQD_kUu3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GccchW0Uu6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpaZPlNJUnPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eTZracyfM1Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXLSeXFnM1HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg06DX24M1Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xbv2gn0WM1L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# consider taking into account the weights of the classes\n",
        "# consider 'early stopping'\n"
      ],
      "metadata": {
        "id": "4qxepNluwT20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_v4 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_model_v4 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")"
      ],
      "metadata": {
        "id": "xw-8Q9hXwT5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layer\n",
        "input_text_v4 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')   # define an input tensor --> the input data to the model will be a string of variable length\n",
        "\n",
        "# Preprocess input text\n",
        "text_preprocessed_v4 = bert_preprocess_v4(input_text_v4)                           # This layer converts the input string into a format that can be understood by the BERT model\n",
        "\n",
        "# Encode input text with BERT\n",
        "output_bert_v4 = bert_model_v4(text_preprocessed_v4)                               # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                                                                # After that, this will be fed into the neural network layers.\n",
        "\n",
        "# Get sequence output\n",
        "sequence_output_v4 = output_bert_v4['sequence_output']\n",
        "\n",
        "# Apply max pooling over sequence output\n",
        "max_pooling_v4 = tf.keras.layers.GlobalMaxPooling1D()(sequence_output_v4)\n",
        "\n",
        "# Apply average pooling over sequence output\n",
        "avg_pooling_v4 = tf.keras.layers.GlobalAveragePooling1D()(sequence_output_v4)\n",
        "\n",
        "# Concatenate max pooled output and pooled output\n",
        "concatenated_v4 = tf.keras.layers.Concatenate()([max_pooling_v4, avg_pooling_v4, output_bert_v4['pooled_output']])\n",
        "\n",
        "# Apply dense layers to concatenated output\n",
        "dense_1_v4 = tf.keras.layers.Dense(512, activation='relu')(concatenated_v4)\n",
        "dense_2_v4 = tf.keras.layers.Dense(256, activation='relu')(dense_1_v4)\n",
        "dense_3_v4 = tf.keras.layers.Dropout(0.1)(dense_2_v4)\n",
        "dense_4_v4 = tf.keras.layers.Dense(128, activation='relu')(dense_3_v4)\n",
        "dense_5_v4 = tf.keras.layers.Dropout(0.1)(dense_4_v4)\n",
        "\n",
        "# Define output layer\n",
        "output_v4 = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(dense_5_v4)\n",
        "\n",
        "# Define the model\n",
        "model_max_avg_pooling_v4 = tf.keras.Model(inputs=input_text_v4, outputs=output_v4)\n",
        "\n",
        "# Freeze the BERT layers\n",
        "bert_model_v4.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "optimizer_v4 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "model_max_avg_pooling_v4.compile(optimizer=optimizer_v4, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iAMRgf93wT7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((trainfeatures, trainlabels)).batch(32) # create a TensorFlow dataset from the input data tensors, which are typically NumPy arrays or Pandas dataframes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((validfeatures, validlabels)).batch(32) "
      ],
      "metadata": {
        "id": "EKcFv9iyp7f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history_max_avg_pooling_v3 = model_max_avg_pooling_v3.fit(train_dataset, epochs=30, class_weight=class_weights_dict, validation_data=val_dataset)\n",
        "\n",
        "# compute class weights\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=binarizer.classes_, y=trainlabels_original)\n",
        "\n",
        "# create a dictionary of class weights\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "history_max_avg_pooling_v4 = model_max_avg_pooling_v4.fit(train_dataset, epochs=30, validation_data=val_dataset, class_weight=class_weights_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "JphSbxxwqOaQ",
        "outputId": "c2c0fdcf-5cd6-44ac-8d15-4d5326483a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "398/398 [==============================] - 95s 218ms/step - loss: 2.1184 - accuracy: 0.3146 - val_loss: 1.6025 - val_accuracy: 0.5138\n",
            "Epoch 2/30\n",
            "398/398 [==============================] - 81s 202ms/step - loss: 1.4506 - accuracy: 0.5385 - val_loss: 1.1924 - val_accuracy: 0.6369\n",
            "Epoch 3/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 1.1436 - accuracy: 0.6422 - val_loss: 0.9988 - val_accuracy: 0.6878\n",
            "Epoch 4/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.9741 - accuracy: 0.6933 - val_loss: 0.8825 - val_accuracy: 0.7189\n",
            "Epoch 5/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.8776 - accuracy: 0.7256 - val_loss: 0.8062 - val_accuracy: 0.7421\n",
            "Epoch 6/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.7889 - accuracy: 0.7542 - val_loss: 0.7335 - val_accuracy: 0.7648\n",
            "Epoch 7/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.7237 - accuracy: 0.7781 - val_loss: 0.7068 - val_accuracy: 0.7758\n",
            "Epoch 8/30\n",
            "398/398 [==============================] - 78s 197ms/step - loss: 0.6697 - accuracy: 0.7869 - val_loss: 0.6686 - val_accuracy: 0.7808\n",
            "Epoch 9/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.6247 - accuracy: 0.8037 - val_loss: 0.6517 - val_accuracy: 0.7877\n",
            "Epoch 10/30\n",
            "398/398 [==============================] - 79s 198ms/step - loss: 0.5801 - accuracy: 0.8197 - val_loss: 0.6164 - val_accuracy: 0.7940\n",
            "Epoch 11/30\n",
            "135/398 [=========>....................] - ETA: 42s - loss: 0.5469 - accuracy: 0.8241"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-717cddf77d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclass_weights_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory_max_avg_pooling_v4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_max_avg_pooling_v4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history_max_avg_pooling_v3.history['accuracy'])\n",
        "plt.plot(history_max_avg_pooling_v3.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d4EhZSY-p7ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ID5FfQs8udQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37fMew6LqEX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKgb86WLqEaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nAFD556MqEcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7z_nM8qjqEfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ItlCSo0qEhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NfveUY0uqEkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHPxr9HwNupJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fJpcHdTkP_dV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes"
      ],
      "metadata": {
        "id": "LWKSOkQ5P9bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   서빙:\n",
        "\n",
        "    *   데이터를 받으면 ML 모델의 predict 함수를 부른 다음에 그 결과값을 반환하는 일련의 행위 자체를, 사용자가 직접 코드를 돌려보는게 아니라 서버에서 API 형태로 제공하는 서비스\n",
        "    *   이를 위해서는, 그러한 모델이 (혹은 API 서버가) OS 라던지 특정 Python 패키지에 의존성이 없도록 container 나 VM 기반으로 패키징 되어있어야됨 → __모델 패키징__\n",
        "          *    기본적인 Rest API 서빙 framework: *Docker*, *Flask*, *FastAPI*\n",
        "          *    ML 모델에 특화된 API 서빙 framework: BentoML, *Kubeflow*, TFServing, seldon-core\n",
        "\n",
        "    *   서빙 후에도 환경이 제대로 돌아가고 있는지, model의 성능이 떨어지고 있지 않는지와 같은 metric 을 지속적으로 모니터링해야되고, 문제가 생기면 알람을 받고, 이러한 것들을 자동화해야됨 → 서빙 모니터링\n",
        "          *    Prometheus, Grafana, Thanos \n",
        "    *   서빙 시, 모델의 성능이 떨어지면 예전 모델로 롤백 한다거나 A/B Testing을 한다거나 이러한 성능 확인을 위해서 이전 모델 학습과정 전체를 다시 돌려보고 싶은 경우가 생길 수 있는데 이를 위해서는 모델 개발 단계부터 단순한 파이썬 코드가 아니라 특정한 파이프라인 형태로 개발을 해야 재사용이 가능하고 재현이 가능함 → 파이프라인 매니징\n",
        "          *   Kubeflow, argo workflows, Airflow\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oIsP9j99QDHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See this video for ModelDB (model management using Kubeflow)\n",
        "# https://www.youtube.com/watch?v=6wWdNg0GMV4\n"
      ],
      "metadata": {
        "id": "CDul1ShDNumj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DUNZ1nW-Le0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PC5L7isTQBes"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_txGw6H-LiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1\")\n",
        "\n",
        "def intent_classification_bert():\n",
        "  \n",
        "  # Initializing the BERT layers\n",
        "  input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text') # define an input tensor --> the input data to the model will be a string of variable length\n",
        "  text_preprocessed = bert_preprocess(input_text) # This layer converts the input string into a format that can be understood by the BERT model\n",
        "  output_bert = bert_model(text_preprocessed) # This layer encodes the input text using the BERT model and returns the encoded outputs\n",
        "                                              # After that, this will be fed into the neural network layers.\n",
        "\n",
        "  # Initializing the neural network layers\n",
        "  encoded_text = output_bert['pooled_output']\n",
        "  layer_1 = tf.keras.layers.Dense(512, activation='relu')(encoded_text)\n",
        "  layer_2 = tf.keras.layers.Dense(256, activation='relu')(layer_1)\n",
        "  layer_3 = tf.keras.layers.Dense(128, activation='relu')(layer_2)\n",
        "  layer_4 = tf.keras.layers.Dropout(0.1)(layer_3) # This layer will be used to prevent model overfitting\n",
        "                                                                                 # We will use 0.1% of the neurons to handle overfitting\n",
        "  output = tf.keras.layers.Dense(trainlabels.shape[1], activation='softmax')(layer_4)  # It only has one neuron. We also initialize the activation function as sigmoid. \n",
        "                                                                                 # sigmoid is used when we have output values that between 0 and 1. \n",
        "                                                                                 # In our case, when making predictions, \n",
        "                                                                                 # the prediction probability will lie between 0 and 1. That’s why it is best suited.\n",
        "                                                                                 # We also name the layer as output because this is our output layer.\n",
        "  return tf.keras.Model(input_text, output)"
      ],
      "metadata": {
        "id": "OUN8D3SiSU2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = intent_classification_bert()\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True) # Since this is a non-binary classification problem and the model outputs probabilities, \n",
        "                                                                 # you’ll use losses.CategoricalCrossentropy loss function.\n",
        "metrics = tf.metrics.CategoricalAccuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOCI10Y6SU4S",
        "outputId": "914e5ff2-f105-442b-86db-9450edac290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20\n",
        "optimizer=tf.keras.optimizers.Adam(1e-5)\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "zEcVTpzZSU63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier_model.fit(x=trainfeatures, y=trainlabels,\n",
        "                               validation_data=(validfeatures,validlabels),\n",
        "                               batch_size=32,\n",
        "                               #class_weight=class_weights_dict,\n",
        "                               epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpKPOFsDSU9H",
        "outputId": "01b54abc-dd06-42e5-9680-6b013123cf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "398/398 [==============================] - ETA: 0s - loss: 2.5312 - categorical_accuracy: 0.1350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r398/398 [==============================] - 99s 219ms/step - loss: 2.5312 - categorical_accuracy: 0.1350 - val_loss: 2.4293 - val_categorical_accuracy: 0.2220\n",
            "Epoch 2/20\n",
            "398/398 [==============================] - 87s 218ms/step - loss: 2.3493 - categorical_accuracy: 0.2544 - val_loss: 2.2450 - val_categorical_accuracy: 0.3194\n",
            "Epoch 3/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 2.1798 - categorical_accuracy: 0.3273 - val_loss: 2.0829 - val_categorical_accuracy: 0.3728\n",
            "Epoch 4/20\n",
            "398/398 [==============================] - 82s 206ms/step - loss: 2.0371 - categorical_accuracy: 0.3653 - val_loss: 1.9543 - val_categorical_accuracy: 0.4130\n",
            "Epoch 5/20\n",
            "398/398 [==============================] - 87s 218ms/step - loss: 1.9231 - categorical_accuracy: 0.4022 - val_loss: 1.8528 - val_categorical_accuracy: 0.4400\n",
            "Epoch 6/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.8315 - categorical_accuracy: 0.4286 - val_loss: 1.7696 - val_categorical_accuracy: 0.4614\n",
            "Epoch 7/20\n",
            "398/398 [==============================] - 87s 220ms/step - loss: 1.7533 - categorical_accuracy: 0.4540 - val_loss: 1.6989 - val_categorical_accuracy: 0.4843\n",
            "Epoch 8/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.6893 - categorical_accuracy: 0.4766 - val_loss: 1.6381 - val_categorical_accuracy: 0.5025\n",
            "Epoch 9/20\n",
            "398/398 [==============================] - 87s 217ms/step - loss: 1.6306 - categorical_accuracy: 0.4912 - val_loss: 1.5833 - val_categorical_accuracy: 0.5229\n",
            "Epoch 10/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.5839 - categorical_accuracy: 0.5054 - val_loss: 1.5397 - val_categorical_accuracy: 0.5292\n",
            "Epoch 11/20\n",
            "398/398 [==============================] - 86s 215ms/step - loss: 1.5430 - categorical_accuracy: 0.5193 - val_loss: 1.5012 - val_categorical_accuracy: 0.5349\n",
            "Epoch 12/20\n",
            "398/398 [==============================] - 81s 204ms/step - loss: 1.5006 - categorical_accuracy: 0.5319 - val_loss: 1.4654 - val_categorical_accuracy: 0.5540\n",
            "Epoch 13/20\n",
            "398/398 [==============================] - 85s 213ms/step - loss: 1.4675 - categorical_accuracy: 0.5410 - val_loss: 1.4320 - val_categorical_accuracy: 0.5625\n",
            "Epoch 14/20\n",
            "398/398 [==============================] - 87s 219ms/step - loss: 1.4385 - categorical_accuracy: 0.5490 - val_loss: 1.4095 - val_categorical_accuracy: 0.5669\n",
            "Epoch 15/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.4036 - categorical_accuracy: 0.5622 - val_loss: 1.3770 - val_categorical_accuracy: 0.5810\n",
            "Epoch 16/20\n",
            "398/398 [==============================] - 86s 216ms/step - loss: 1.3851 - categorical_accuracy: 0.5667 - val_loss: 1.3545 - val_categorical_accuracy: 0.5823\n",
            "Epoch 17/20\n",
            "398/398 [==============================] - 80s 201ms/step - loss: 1.3565 - categorical_accuracy: 0.5804 - val_loss: 1.3331 - val_categorical_accuracy: 0.5864\n",
            "Epoch 18/20\n",
            "398/398 [==============================] - 86s 217ms/step - loss: 1.3306 - categorical_accuracy: 0.5844 - val_loss: 1.3143 - val_categorical_accuracy: 0.5886\n",
            "Epoch 19/20\n",
            "398/398 [==============================] - 85s 215ms/step - loss: 1.3102 - categorical_accuracy: 0.5867 - val_loss: 1.2982 - val_categorical_accuracy: 0.5930\n",
            "Epoch 20/20\n",
            "398/398 [==============================] - 85s 214ms/step - loss: 1.2881 - categorical_accuracy: 0.5946 - val_loss: 1.2769 - val_categorical_accuracy: 0.6077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YejhDbid3vM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DmSmaH0d30G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_XSSnAdUq_on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIke2RGNujtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}